#%% Importation des librairies
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt

from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

#%% Chargement des donn√©es
df = pd.read_csv("data/train.csv")

#%% Pr√©traitement des donn√©es

# S√©lection des features pertinentes
features = ["Pclass", "Sex", "Age", "SibSp", "Parch", "Fare", "Embarked"]
target = "Survived"
df = df[features + [target]]

# S√©paration X et y
X = df.drop(columns=[target])
y = df[target]

# Cr√©ation du pipeline de pr√©traitement
numerical_features = ["Age", "Fare", "SibSp", "Parch"]
categorical_features = ["Pclass", "Sex", "Embarked"]

numerical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="median")),
    ("scaler", StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ("imputer", SimpleImputer(strategy="most_frequent")),
    ("encoder", OneHotEncoder(handle_unknown="ignore"))
])

preprocessor = ColumnTransformer(transformers=[
    ("num", numerical_transformer, numerical_features),
    ("cat", categorical_transformer, categorical_features)
])

#%% S√©paration train / test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#%% Entra√Ænement du mod√®le
model = Pipeline(steps=[
    ("preprocessor", preprocessor),
    ("classifier", LogisticRegression(max_iter=1000))
])

model.fit(X_train, y_train)

#%% √âvaluation
y_pred = model.predict(X_test)
acc = accuracy_score(y_test, y_pred)
f1 = f1_score(y_test, y_pred)

print(f"üîπ Accuracy : {acc:.4f}")
print(f"üîπ F1-score : {f1:.4f}")

# Matrice de confusion
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Non surv√©cu", "Surv√©cu"], yticklabels=["Non surv√©cu", "Surv√©cu"])
plt.title("Matrice de confusion")
plt.xlabel("Pr√©diction")
plt.ylabel("R√©el")
plt.show()

#%% Validation crois√©e (optionnel)
cv_scores = cross_val_score(model, X, y, cv=5, scoring="accuracy")
print(f"üîπ Cross-validation accuracy : {cv_scores.mean():.4f} ¬± {cv_scores.std():.4f}")
